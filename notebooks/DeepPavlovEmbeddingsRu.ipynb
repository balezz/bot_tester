{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZfCxNic5mlQ"
   },
   "source": [
    "# Deep Pavlov RuBert for sentense embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uLrXp0vzxFN"
   },
   "source": [
    "## 1 Download and extract BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsxdRRTs5f-y"
   },
   "outputs": [],
   "source": [
    "! wget http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_pt.tar.gz\n",
    "! tar -xf rubert_cased_L-12_H-768_A-12_pt.tar.gz\n",
    "! rm rubert_cased_L-12_H-768_A-12_pt.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieppkrjtz6Rs"
   },
   "source": [
    "## 2 Install Deep Pavlov framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_F4K6tI7We3"
   },
   "outputs": [],
   "source": [
    "! pip install deeppavlov transformers\n",
    "# https://github.com/deepmipt/DeepPavlov/issues/1355\n",
    "! python -m deeppavlov install bert_sentence_embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMu60Vie0FVs"
   },
   "source": [
    "## 3 Build pretrained Russian BERT Pytorch based model  \n",
    "RuBERT was trained on the Russian part of Wikipedia and news data. We used this training data to build vocabulary of Russian subtokens and took multilingual version of BERT-base as initialization for RuBERT   \n",
    "\n",
    "Kuratov, Y., Arkhipov, M. (2019). Adaptation of Deep Bidirectional Multilingual Transformers for Russian Language. arXiv preprint arXiv:1905.07213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dXXN4j16Vp8"
   },
   "outputs": [],
   "source": [
    "from deeppavlov.core.common.file import read_json\n",
    "from deeppavlov import build_model, configs\n",
    "\n",
    "bert_config = read_json(configs.embedder.bert_embedder)\n",
    "bert_config['metadata']['variables']['BERT_PATH'] = '/content/rubert_cased_L-12_H-768_A-12_pt'\n",
    "\n",
    "rubert_model = build_model(bert_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU_xPqk82RZ9"
   },
   "source": [
    "## 4 Вопрос: Что такое искусственный интеллект?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEdJQFBa6VnU"
   },
   "outputs": [],
   "source": [
    "# Первый ответ правильный, второй и третий дали конкурсанты\n",
    "texts = ['это способность компьютера обучаться, принимать решения и выполнять действия, свойственные человеческому интеллекту',\n",
    "         'это свойство интеллектуальных систем выполнять творческие функции, которые традиционно считаются прерогативой человека',\n",
    "         'это алгоритмы для анализа данных, получения выводов или предсказаний в отношении чего-либо']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJSU1OJz5ug7"
   },
   "outputs": [],
   "source": [
    "# Вычисляем эмбеддинги для каждого ответа\n",
    "tokens, token_embs, subtokens, subtoken_embs, sent_max_embs, sent_mean_embs, bert_pooler_outputs = rubert_model(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_O-HToa6Vks",
    "outputId": "5558bfb4-796c-44ab-a237-a88a9e5e3199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 768)\n",
      "(13, 768)\n",
      "(15, 768)\n"
     ]
    }
   ],
   "source": [
    "# Эмбеддинги имеют размер: (количества токенов в ответе, 768)\n",
    "# 768 - длина вектора внутреннего состояния модели RuBERT\n",
    "\n",
    "sentense_embed = []\n",
    "for i in range(3):\n",
    "  print(token_embs[i].shape)\n",
    "  # Усредняем по токенам\n",
    "  sentense_embed.append(token_embs[i].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFYWB8rS6Vh0",
    "outputId": "bce360c3-a0f0-46d7-8186-b6ebee5bf546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расстояние между правильным ответом и ответом первого конкурсанта -  10.903059\n",
      "Расстояние между правильным ответом и ответом второго конкурсанта -  12.4934635\n",
      "Расстояние между ответами конкурсантов -  15.052757\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('Расстояние между правильным ответом и ответом первого конкурсанта - ',\n",
    "      np.linalg.norm(sentense_embed[0] - sentense_embed[1]))\n",
    "\n",
    "print('Расстояние между правильным ответом и ответом второго конкурсанта - ',\n",
    "    np.linalg.norm(sentense_embed[0] - sentense_embed[2]))\n",
    "\n",
    "print('Расстояние между ответами конкурсантов - ',\n",
    "    np.linalg.norm(sentense_embed[1] - sentense_embed[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-61yxUX77BSz"
   },
   "source": [
    "Судя по результатам вычислений, первый конкурсант дал более правильный ответ."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DeepPavlovEmbeddingsRu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
